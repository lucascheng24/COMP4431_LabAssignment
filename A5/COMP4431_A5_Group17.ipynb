{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GradientBoosting classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_public: (30000, 58)\n",
      "Shape of y_public: (30000,)\n",
      "Shape of X_private: (5000, 58)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def read_data_from_csv(path):\n",
    "    \"\"\"Load datasets from CSV files.\n",
    "    Args:\n",
    "        path (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        X (np.ndarray): Features of samples.\n",
    "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
    "    \"\"\"\n",
    "    assert os.path.exists(path), f'File not found: {path}!'\n",
    "    assert os.path.splitext(path)[\n",
    "        -1] == '.csv', f'Unsupported file type {os.path.splitext(path)[-1]}!'\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "    column_list = data.columns.values.tolist()\n",
    "\n",
    "    if 'Label' in column_list:\n",
    "        # for the public dataset, label column is provided.\n",
    "        column_list.remove('Label')\n",
    "        X = data[column_list].values\n",
    "        y = data['Label'].astype('int').values\n",
    "        return X, y\n",
    "    else:\n",
    "        # for the private dataset, label column is not provided.\n",
    "        X = data[column_list].values\n",
    "        return X\n",
    "    \n",
    "def normalize(df: pd.DataFrame):\n",
    "    df_norm = df\n",
    "    # Continuous features   1-11, 18-29, 38-58\n",
    "    df_1T11 = df_norm.iloc[:, 0:11]  \n",
    "    df_18T19 = df_norm.iloc[:, 17:29]\n",
    "    df_38T58 = df_norm.iloc[:, 37:58]\n",
    "\n",
    "    # Categorical features  12-17, 30-37 \n",
    "    df_12T17 = df_norm.iloc[:, 11:17]\n",
    "    df_30T37 = df_norm.iloc[:, 29:37]\n",
    "\n",
    "    # concatenating along columns\n",
    "    horizontal_Continuous_concat = pd.concat([df_1T11, df_18T19, df_38T58], axis=1)\n",
    "    horizontal_Categorical_concat = pd.concat([df_12T17, df_30T37], axis=1)\n",
    "\n",
    "    # Normalize the numeric features\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_Continuous = pd.DataFrame(scaler.fit_transform(pd.DataFrame(horizontal_Continuous_concat)))\n",
    "\n",
    "    # change Categorical features data type from float to boolean\n",
    "    for column in horizontal_Categorical_concat:\n",
    "        horizontal_Categorical_concat[column] = horizontal_Categorical_concat[column].astype(bool)\n",
    "\n",
    "    print(horizontal_Continuous_concat.shape)\n",
    "    print(horizontal_Categorical_concat.shape)\n",
    "    \n",
    "    #  combine to full dataset\n",
    "    df_fullConcat = pd.concat([normalized_Continuous, horizontal_Categorical_concat], axis=1)\n",
    "\n",
    "    return df_fullConcat\n",
    "\n",
    "X_public, y_public = read_data_from_csv('assignment_5_public.csv')\n",
    "print('Shape of X_public:', X_public.shape)  # n_sample, m_feature (30000, 58)\n",
    "print('Shape of y_public:', y_public.shape)  # n_sample (30000,)\n",
    "\n",
    "df_train_x = pd.DataFrame(X_public)\n",
    "df_train_y = pd.DataFrame(y_public)\n",
    "# normalized_x = normalize(df_train_x) not scalling is better than normalized\n",
    "\n",
    "# scores = cross_val_score(GBoost_clf, normalized_x, y_public, cv = 8)\n",
    "# print(\"Cross Validation Scores: \", scores)\n",
    "# print(\"\\nAverage CV Score: \", scores.mean())      #   Average CV Score:  0.671\n",
    "\n",
    "# Construct model\n",
    "GBoost_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "\n",
    "\n",
    "# fit model and generate prediction\n",
    "X_private = read_data_from_csv('assignment_5_private.csv')\n",
    "print('Shape of X_private:', X_private.shape)  # k_sample, m_feature (5000, 58)\n",
    "df_test_x = pd.DataFrame(X_private)\n",
    "# normalized_test_x = normalize(df_test_x)\n",
    "\n",
    "\n",
    "GBoost_clf.fit(df_train_x, y_public)\n",
    "preds = GBoost_clf.predict(df_test_x)\n",
    "\n",
    "submission = pd.DataFrame({'Label': preds})\n",
    "submission.to_csv('assignment_5.csv', index=True, index_label='Id')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
