{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PKnkQ2JYVnp"
      },
      "source": [
        "# Part 1. Problem and Reference Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZqt2Yb4I6x"
      },
      "source": [
        "## 1.1 The Problem\n",
        "\n",
        "As an expert in artificial intelligence, banks are looking to your expertise to predict credit card approvals. They provide you with a credit card database and your task is to determine whether the credit card application should be approved based on the variables within it.\n",
        "\n",
        "To maintain confidentiality, all variable names and values have been anonymized and replaced with symbols.\n",
        "\n",
        "| Variable  names | Role    | Type        | Value                                        |\n",
        "| --------------- | ------- | ----------- | -------------------------------------------- |\n",
        "| Feature 1       | Feature | Continuous  |                                              |\n",
        "| Feature 2       | Feature | Continuous  |                                              |\n",
        "| Feature 3       | Feature | Continuous  |                                              |\n",
        "| Feature 4       | Feature | Continuous  |                                              |\n",
        "| Feature 5       | Feature | Continuous  |                                              |\n",
        "| Feature 6       | Feature | Continuous  |                                              |\n",
        "| Feature 7       | Feature | Categorical | 0,1                                          |\n",
        "| Feature 8       | Feature | Categorical | 0,1                                          |\n",
        "| Feature 9       | Feature | Categorical | 0,1                                          |\n",
        "| Feature 10      | Feature | Categorical | 0,1                                          |\n",
        "| Feature 11      | Feature | Categorical | 1,2,3                                        |\n",
        "| Feature 12      | Feature | Categorical | 1,2,3                                        |\n",
        "| Feature 13      | Feature | Categorical | 1,2,3,4,5,6,7,8,9                            |\n",
        "| Feature 14      | Feature | Categorical | 1,2,3,4,5,6,7,8,9,10,11,12,13,14             |\n",
        "| Label           | Label   | Categorical | 0,1 (0 for non-approval and 1 for  approval) |\n",
        "\n",
        "The bank required the use of decision tree-based models, emphasizing the importance of interpretability in the decision-making process. Try using a decision tree-based model for the best results! You will train and validate a decision tree-based model using 590 samples in the public dataset. Your results will then be on 100 samples in the private dataset, and your performance on the private dataset will be used as the final score.\n",
        "\n",
        "Hint 1: Cross-validation is important.\n",
        "\n",
        "Hint 2: Consider preprocessing and feature engineering if it benefits your model.\n",
        "\n",
        "Hint 3: Optimize hyperparameters for improved performance.\n",
        "\n",
        "Hint 4: Other techniques like pre-pruning and post-pruning can be applied.\n",
        "\n",
        "Note:\n",
        "* Please download the public dataset from https://drive.google.com/file/d/1gQ_hA5DLMYQHcqGmkSaq2w-Sm-OLAKfZ/view?usp=sharing\n",
        "* Please download the private dataset from https://drive.google.com/file/d/1s1xhpfWKWeACf3SiPAmEhCs8dfwmSVEP/view?usp=sharing\n",
        "* Please download the ground-truth for private dataset from https://drive.google.com/file/d/1yS5Qi81CJwxdhunUDNoz-2_D9QWzVyLN/view?usp=share_link\n",
        "* Please use the following Python template for submission. (You can copy the code below from lab6-Exercise.ipynb)\n",
        "* Your results will be evaluated on 100 samples in the private dataset (The labels will released in Lab 7).\n",
        "\n",
        "```\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def read_data_from_csv(path):\n",
        "    \"\"\"Load datasets from CSV files.\n",
        "    Args:\n",
        "        path (str): Path to the CSV file.\n",
        "    Returns:\n",
        "        X (np.ndarray): Features of samples.\n",
        "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
        "    \"\"\"\n",
        "    assert os.path.exists(path), f'File not found: {path}!'\n",
        "    assert os.path.splitext(path)[\n",
        "        -1] == '.csv', f'Unsupported file type {os.path.splitext(path)[-1]}!'\n",
        "\n",
        "    data = pd.read_csv(path)\n",
        "    column_list = data.columns.values.tolist()\n",
        "\n",
        "    if 'Label' in column_list:\n",
        "        # for the public dataset, label column is provided.\n",
        "        column_list.remove('Label')\n",
        "        X = data[column_list].values\n",
        "        y = data['Label'].astype('int').values\n",
        "        return X, y\n",
        "    else:\n",
        "        # for the private dataset, label column is not provided.\n",
        "        X = data[column_list].values\n",
        "        return X\n",
        "\n",
        "X_public, y_public = read_data_from_csv('assignment_3_public.csv')\n",
        "print('Shape of X_public:', X_public.shape)  # n_sample, m_feature (590, 14)\n",
        "print('Shape of y_public:', y_public.shape)  # n_sample (590,)\n",
        "\n",
        "'''\n",
        "CODE HERE!\n",
        "'''\n",
        "\n",
        "X_private = read_data_from_csv('assignment_3_private.csv')\n",
        "print('Shape of X_private:', X_private.shape)  # k_sample, m_feature (100, 14)\n",
        "\n",
        "# remove and make your own predictions.\n",
        "preds = np.full(len(X_private), -1,\n",
        "                dtype=int)\n",
        "'''\n",
        "CODE HERE!\n",
        "e.g.,\n",
        "preds = np.full(len(X_private), -1, dtype=int)\n",
        "'''\n",
        "\n",
        "submission = pd.DataFrame({'Label': preds})\n",
        "submission.to_csv('assignment_3.csv', index=True, index_label='Id')\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BEqyIfr4I6z"
      },
      "source": [
        "## 1.2 Refernce Code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may need to revise the generated code. Here is what I finally got. Some useful and simple techniques that may be included are:\n",
        "\n",
        "- Utilizing five-fold cross-validation to select the hyperparameters with the best average performance, such as max_leaf_nodes\n",
        "- Ensembling the models trained during five-fold cross-validation\n",
        "- Handling missing values, such as using the most frequent value\n",
        "- Processing categorical variables, such as one-hot encoding"
      ],
      "metadata": {
        "id": "GitLNU0oPIa_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuxWwnE04I6z",
        "outputId": "2044c300-7c03-49df-834d-d3fa825bb22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_public: (590, 14)\n",
            "Shape of y_public: (590,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc: 0.8593220338983051: 100%|██████████| 24/24 [00:00<00:00, 43.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_leaf_nodes': 10, 'imputer': 'most_frequent', 'category': 'onehot'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "def read_data_from_csv(path):\n",
        "    \"\"\"Load datasets from CSV files.\n",
        "    Args:\n",
        "        path (str): Path to the CSV file.\n",
        "    Returns:\n",
        "        X (np.ndarray): Features of samples.\n",
        "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
        "    \"\"\"\n",
        "    assert os.path.exists(path), f'File not found: {path}!'\n",
        "    assert os.path.splitext(path)[\n",
        "        -1] == '.csv', f'Unsupported file type {os.path.splitext(path)[-1]}!'\n",
        "\n",
        "    data = pd.read_csv(path)\n",
        "    column_list = data.columns.values.tolist()\n",
        "\n",
        "    if 'Label' in column_list:\n",
        "        # for the public dataset, label column is provided.\n",
        "        column_list.remove('Label')\n",
        "        X = data[column_list].values\n",
        "        y = data['Label'].astype('int').values\n",
        "        return X, y\n",
        "    else:\n",
        "        # for the private dataset, label column is not provided.\n",
        "        X = data[column_list].values\n",
        "        return X\n",
        "\n",
        "\n",
        "X_public, y_public = read_data_from_csv('assignment_3_public.csv')\n",
        "print('Shape of X_public:', X_public.shape)  # n_sample, m_feature (590, 14)\n",
        "print('Shape of y_public:', y_public.shape)  # n_sample (590,)\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "\n",
        "def seed_everthing(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "seed_everthing(seed=42)\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def make_grid(pars_dict):\n",
        "    keys = pars_dict.keys()\n",
        "    combinations = itertools.product(*pars_dict.values())\n",
        "    outputs = [dict(zip(keys, combination)) for combination in combinations]\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# something really practical.\n",
        "param_grid = {\n",
        "    'max_leaf_nodes': [None, 5, 10, 15],\n",
        "    'imputer': [None, 'median', 'most_frequent'],\n",
        "    'category': [None, 'onehot']\n",
        "}\n",
        "\n",
        "param_list = make_grid(param_grid)\n",
        "\n",
        "test_acc = 0.0\n",
        "best_param = None\n",
        "best_models = None\n",
        "best_imputer = None\n",
        "best_category = None\n",
        "\n",
        "pbar = tqdm(total=len(param_list))\n",
        "for param in param_list:\n",
        "    processed_X_public = X_public.copy()\n",
        "\n",
        "    if param['imputer'] == 'median':\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        imputer.fit(processed_X_public)\n",
        "        processed_X_public = imputer.transform(processed_X_public)\n",
        "    elif param['imputer'] == 'most_frequent':\n",
        "        imputer = SimpleImputer(strategy='most_frequent')\n",
        "        imputer.fit(processed_X_public)\n",
        "        processed_X_public = imputer.transform(processed_X_public)\n",
        "    else:\n",
        "        # you can do more imputation methods here.\n",
        "        imputer = None\n",
        "\n",
        "    if param['category'] == 'onehot':\n",
        "        # the 7th column to the last column are categorical features.\n",
        "        from sklearn.preprocessing import OneHotEncoder\n",
        "        est = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "        est.fit(processed_X_public[:, 6:])\n",
        "        processed_X_public = np.concatenate([processed_X_public[:, :6], est.transform(processed_X_public[:, 6:])], axis=1)\n",
        "        category = est\n",
        "    else:\n",
        "        category = None\n",
        "\n",
        "    k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    preds = []\n",
        "    gts = []\n",
        "    models = []\n",
        "\n",
        "    for fold_idx, (train_idx, test_idx) in enumerate(k_fold.split(processed_X_public)):\n",
        "        X_train, X_test = processed_X_public[train_idx], processed_X_public[test_idx]\n",
        "        y_train, y_test = y_public[train_idx], y_public[test_idx]\n",
        "\n",
        "        # filter keys that are not parameters of DecisionTreeClassifier.\n",
        "        clf_param = {k: v for k, v in param.items() if k in DecisionTreeClassifier().get_params().keys()}\n",
        "        model = DecisionTreeClassifier(**clf_param)\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_test)\n",
        "\n",
        "        preds.append(pred.tolist())\n",
        "        gts.append(y_test.tolist())\n",
        "\n",
        "        models.append(model)\n",
        "\n",
        "    cur_acc = np.sum(np.array(preds) == np.array(gts)) / len(y_public)\n",
        "    pbar.update(1)\n",
        "    pbar.set_description(f'acc: {cur_acc}')\n",
        "\n",
        "    if cur_acc > test_acc:\n",
        "        test_acc = cur_acc\n",
        "        best_param = param\n",
        "        best_models = models\n",
        "        best_imputer = imputer\n",
        "        best_category = category\n",
        "\n",
        "pbar.close()\n",
        "print(best_param)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2. Demo of Interactions with ChatGPT\n",
        "\n",
        "You can use either of the approaches to interact with ChatGPT:\n",
        "- Access https://genai.polyu.edu.hk/ to interact with ChatGPT.\n",
        "- Use OpenAI API to interact with ChatGPT via code."
      ],
      "metadata": {
        "id": "EBI1lbi563i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Preparations"
      ],
      "metadata": {
        "id": "mdm8gTK766ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "from typing import List\n",
        "\n",
        "# Set the seed\n",
        "def seed_everything(seed=0):\n",
        "    np.random.seed(seed)\n",
        "seed_everything()\n",
        "\n",
        "# Install OpenAI package\n",
        "!pip install openai\n",
        "\n",
        "# Import OpenAI and set the API key\n",
        "import openai\n",
        "openai.api_key = 'OpenAI_API_Key' # Replace with your own OpenAI API Key\n",
        "\n",
        "# Define the function of get response from ChatGPT\n",
        "_messages = []\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo-0613\"):\n",
        "    _messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=_messages,\n",
        "        temperature=0.0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    content = response.choices[0].message[\"content\"]\n",
        "    _messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "    return content\n",
        "\n",
        "\n",
        "# Set display format\n",
        "import html\n",
        "from IPython.core.display import display, HTML\n",
        "css_content = \"\"\".cs-message{box-sizing:border-box;font-size:1em;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;color:#000000de;display:flex;flex-direction:row;padding:0;background-color:transparent;overflow:hidden;border-radius:0}.cs-message:not(:only-child){margin:.2em 0 0}.cs-message__avatar{box-sizing:border-box;margin:0 8px 0 0;display:flex;flex-direction:column;justify-content:flex-end;width:42px}.cs-message__content-wrapper{box-sizing:border-box;display:flex;flex-direction:column}.cs-message__content{box-sizing:border-box;color:#000000de;background-color:#c6e3fa;margin-top:0;padding:.6em .9em;border-radius:.7em;white-space:pre-wrap;overflow-wrap:anywhere;word-break:break-word;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;font-weight:400;font-size:.91em;font-variant:normal}.cs-message--incoming{color:#000000de;background-color:transparent;margin-right:auto}.cs-message--incoming .cs-message__avatar{margin:0 8px 0 0}.cs-message--incoming .cs-message__content{color:#000000de;background-color:#c6e3fa;border-radius:0 .7em .7em 0}.cs-message--outgoing{color:#000000de;background-color:transparent;margin-left:auto;justify-content:flex-end}.cs-message--outgoing .cs-message__avatar{order:1;margin:0 0 0 8px}.cs-message--outgoing .cs-message__content{color:#000000de;background-color:#6ea9d7;border-radius:.7em 0 0 .7em}.cs-message.cs-message--incoming.cs-message--single{border-radius:0}.cs-message.cs-message--incoming.cs-message--single:not(:first-child){margin-top:.4em}.cs-message.cs-message--incoming.cs-message--single .cs-message__content{border-radius:0 .7em .7em}.cs-message.cs-message--outgoing.cs-message--single{border-radius:0}.cs-message.cs-message--outgoing.cs-message--single .cs-message__content{border-radius:.7em .7em 0}.cs-avatar{position:relative;width:42px;height:42px;border-radius:50%;box-sizing:border-box}.cs-avatar>img{box-sizing:border-box;width:100%;height:100%;border-radius:50%}.cs-avatar.cs-avatar--md{width:42px;height:42px;min-width:42px;min-height:42px\n",
        "\"\"\"\n",
        "html_content = \"\"\"\n",
        "    <section aria-label=\"User\" class=\"cs-message cs-message--outgoing cs-message--single\" data-cs-message=\"\">\n",
        "        <div class=\"cs-message__avatar\">\n",
        "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/user-8c5a41ea.png\" alt=\"PolyU\"> </div>\n",
        "        </div>\n",
        "        <div class=\"cs-message__content-wrapper\">\n",
        "            <div class=\"cs-message__content\">\n",
        "                <div class=\"cs-message__custom-content\">hello</div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </section>\n",
        "    <section aria-label=\"ChatGPT\" class=\"cs-message cs-message--incoming cs-message--single\" data-cs-message=\"\">\n",
        "        <div class=\"cs-message__avatar\">\n",
        "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/chatbot-08b96590.png\" alt=\"PolyU\"> </div>\n",
        "        </div>\n",
        "        <div class=\"cs-message__content-wrapper\">\n",
        "            <div class=\"cs-message__content\">\n",
        "                <div class=\"cs-message__custom-content\">Hello! How can I assist you today?</div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </section>\n",
        "\"\"\"\n",
        "def generate_html(messages, n=2):\n",
        "    if n is not None:\n",
        "      messages = messages[-n:]\n",
        "\n",
        "    html_parts = []\n",
        "    user_template = \"\"\"\n",
        "    <section aria-label=\"User\" class=\"cs-message cs-message--outgoing cs-message--single\" data-cs-message=\"\">\n",
        "        <div class=\"cs-message__avatar\">\n",
        "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/user-8c5a41ea.png\" alt=\"PolyU\"> </div>\n",
        "        </div>\n",
        "        <div class=\"cs-message__content-wrapper\">\n",
        "            <div class=\"cs-message__content\">\n",
        "                <div class=\"cs-message__custom-content\">{content}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </section>\n",
        "    \"\"\"\n",
        "\n",
        "    assistant_template = \"\"\"\n",
        "    <section aria-label=\"ChatGPT\" class=\"cs-message cs-message--incoming cs-message--single\" data-cs-message=\"\">\n",
        "        <div class=\"cs-message__avatar\">\n",
        "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/chatbot-08b96590.png\" alt=\"PolyU\"> </div>\n",
        "        </div>\n",
        "        <div class=\"cs-message__content-wrapper\">\n",
        "            <div class=\"cs-message__content\">\n",
        "                <div class=\"cs-message__custom-content\">{content}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </section>\n",
        "    \"\"\"\n",
        "\n",
        "    for message in messages:\n",
        "        sanitized_content = html.escape(message[\"content\"])\n",
        "        if message[\"role\"] == \"user\":\n",
        "            html_parts.append(user_template.format(content=sanitized_content))\n",
        "        elif message[\"role\"] == \"assistant\":\n",
        "            html_parts.append(assistant_template.format(content=sanitized_content))\n",
        "\n",
        "    return \"\".join(html_parts) + f\"<style>{css_content}</style>\""
      ],
      "metadata": {
        "id": "Ka77SacS67yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Interact with ChatGPT"
      ],
      "metadata": {
        "id": "W0QsPLPf6-zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem = '''\n",
        "As an expert in artificial intelligence, banks are looking to your expertise to predict credit card approvals. They provide you with a credit card database and your task is to determine whether the credit card application should be approved based on the variables within it.\n",
        "\n",
        "To maintain confidentiality, all variable names and values have been anonymized and replaced with symbols.\n",
        "\n",
        "| Variable  names | Role    | Type        | Value                                        |\n",
        "| --------------- | ------- | ----------- | -------------------------------------------- |\n",
        "| Feature 1       | Feature | Continuous  |                                              |\n",
        "| Feature 2       | Feature | Continuous  |                                              |\n",
        "| Feature 3       | Feature | Continuous  |                                              |\n",
        "| Feature 4       | Feature | Continuous  |                                              |\n",
        "| Feature 5       | Feature | Continuous  |                                              |\n",
        "| Feature 6       | Feature | Continuous  |                                              |\n",
        "| Feature 7       | Feature | Categorical | 0,1                                          |\n",
        "| Feature 8       | Feature | Categorical | 0,1                                          |\n",
        "| Feature 9       | Feature | Categorical | 0,1                                          |\n",
        "| Feature 10      | Feature | Categorical | 0,1                                          |\n",
        "| Feature 11      | Feature | Categorical | 1,2,3                                        |\n",
        "| Feature 12      | Feature | Categorical | 1,2,3                                        |\n",
        "| Feature 13      | Feature | Categorical | 1,2,3,4,5,6,7,8,9                            |\n",
        "| Feature 14      | Feature | Categorical | 1,2,3,4,5,6,7,8,9,10,11,12,13,14             |\n",
        "| Label           | Label   | Categorical | 0,1 (0 for non-approval and 1 for  approval) |\n",
        "\n",
        "The bank required the use of decision tree-based models, emphasizing the importance of interpretability in the decision-making process. Try using a decision tree-based model for the best results! You will train and validate a decision tree-based model using 590 samples in the public dataset. Your results will then be on 100 samples in the private dataset, and your performance on the private dataset will be used as the final score.\n",
        "'''\n",
        "\n",
        "prompt = '''\n",
        "{problem}\n",
        "Let’s think step by step.\n",
        "'''\n",
        "\n",
        "message = prompt.format(problem=problem)\n",
        "response = get_completion(message)\n",
        "\n",
        "html_content = generate_html(_messages)\n",
        "display(HTML(html_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eM0ggfOX7CYZ",
        "outputId": "3bdbf961-4036-4dc2-98df-b4cabb6d67dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <section aria-label=\"User\" class=\"cs-message cs-message--outgoing cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/user-8c5a41ea.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">\n",
              "\n",
              "As an expert in artificial intelligence, banks are looking to your expertise to predict credit card approvals. They provide you with a credit card database and your task is to determine whether the credit card application should be approved based on the variables within it.\n",
              "\n",
              "To maintain confidentiality, all variable names and values have been anonymized and replaced with symbols.\n",
              "\n",
              "| Variable  names | Role    | Type        | Value                                        |\n",
              "| --------------- | ------- | ----------- | -------------------------------------------- |\n",
              "| Feature 1       | Feature | Continuous  |                                              |\n",
              "| Feature 2       | Feature | Continuous  |                                              |\n",
              "| Feature 3       | Feature | Continuous  |                                              |\n",
              "| Feature 4       | Feature | Continuous  |                                              |\n",
              "| Feature 5       | Feature | Continuous  |                                              |\n",
              "| Feature 6       | Feature | Continuous  |                                              |\n",
              "| Feature 7       | Feature | Categorical | 0,1                                          |\n",
              "| Feature 8       | Feature | Categorical | 0,1                                          |\n",
              "| Feature 9       | Feature | Categorical | 0,1                                          |\n",
              "| Feature 10      | Feature | Categorical | 0,1                                          |\n",
              "| Feature 11      | Feature | Categorical | 1,2,3                                        |\n",
              "| Feature 12      | Feature | Categorical | 1,2,3                                        |\n",
              "| Feature 13      | Feature | Categorical | 1,2,3,4,5,6,7,8,9                            |\n",
              "| Feature 14      | Feature | Categorical | 1,2,3,4,5,6,7,8,9,10,11,12,13,14             |\n",
              "| Label           | Label   | Categorical | 0,1 (0 for non-approval and 1 for  approval) |\n",
              "\n",
              "The bank required the use of decision tree-based models, emphasizing the importance of interpretability in the decision-making process. Try using a decision tree-based model for the best results! You will train and validate a decision tree-based model using 590 samples in the public dataset. Your results will then be on 100 samples in the private dataset, and your performance on the private dataset will be used as the final score.\n",
              "\n",
              "Let’s think step by step.\n",
              "</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    \n",
              "    <section aria-label=\"ChatGPT\" class=\"cs-message cs-message--incoming cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/chatbot-08b96590.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">Step 1: Data Preprocessing\n",
              "- Load the credit card database and examine the data.\n",
              "- Check for missing values and handle them appropriately (e.g., imputation or removal).\n",
              "- Convert categorical variables into numerical representations (e.g., one-hot encoding or label encoding) if necessary.\n",
              "- Split the data into training and validation sets.\n",
              "\n",
              "Step 2: Model Training\n",
              "- Choose a decision tree-based model, such as a traditional decision tree, random forest, or gradient boosting.\n",
              "- Train the model using the training set.\n",
              "- Optimize the model&#x27;s hyperparameters using techniques like grid search or random search.\n",
              "- Evaluate the model&#x27;s performance on the validation set using appropriate metrics (e.g., accuracy, precision, recall, or F1 score).\n",
              "\n",
              "Step 3: Model Evaluation\n",
              "- Once the model is trained and optimized, evaluate its performance on the private dataset.\n",
              "- Calculate the final score based on the model&#x27;s performance on the private dataset.\n",
              "\n",
              "Step 4: Interpretability\n",
              "- Interpret the decision tree-based model to understand the factors that contribute to credit card approval or non-approval.\n",
              "- Analyze the feature importance provided by the model and identify the most influential variables.\n",
              "\n",
              "Step 5: Recommendations\n",
              "- Based on the model&#x27;s interpretation and feature importance, provide recommendations to the bank on improving credit card approval rates.\n",
              "- Suggest potential changes or adjustments to the decision-making process based on the insights gained from the model.\n",
              "\n",
              "Step 6: Continuous Improvement\n",
              "- Continuously monitor and evaluate the model&#x27;s performance over time.\n",
              "- Collect new data and retrain the model periodically to ensure its accuracy and relevance.\n",
              "- Stay updated with the latest advancements in decision tree-based models and interpretability techniques to enhance the model&#x27;s performance and insights.</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    <style>.cs-message{box-sizing:border-box;font-size:1em;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;color:#000000de;display:flex;flex-direction:row;padding:0;background-color:transparent;overflow:hidden;border-radius:0}.cs-message:not(:only-child){margin:.2em 0 0}.cs-message__avatar{box-sizing:border-box;margin:0 8px 0 0;display:flex;flex-direction:column;justify-content:flex-end;width:42px}.cs-message__content-wrapper{box-sizing:border-box;display:flex;flex-direction:column}.cs-message__content{box-sizing:border-box;color:#000000de;background-color:#c6e3fa;margin-top:0;padding:.6em .9em;border-radius:.7em;white-space:pre-wrap;overflow-wrap:anywhere;word-break:break-word;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;font-weight:400;font-size:.91em;font-variant:normal}.cs-message--incoming{color:#000000de;background-color:transparent;margin-right:auto}.cs-message--incoming .cs-message__avatar{margin:0 8px 0 0}.cs-message--incoming .cs-message__content{color:#000000de;background-color:#c6e3fa;border-radius:0 .7em .7em 0}.cs-message--outgoing{color:#000000de;background-color:transparent;margin-left:auto;justify-content:flex-end}.cs-message--outgoing .cs-message__avatar{order:1;margin:0 0 0 8px}.cs-message--outgoing .cs-message__content{color:#000000de;background-color:#6ea9d7;border-radius:.7em 0 0 .7em}.cs-message.cs-message--incoming.cs-message--single{border-radius:0}.cs-message.cs-message--incoming.cs-message--single:not(:first-child){margin-top:.4em}.cs-message.cs-message--incoming.cs-message--single .cs-message__content{border-radius:0 .7em .7em}.cs-message.cs-message--outgoing.cs-message--single{border-radius:0}.cs-message.cs-message--outgoing.cs-message--single .cs-message__content{border-radius:.7em .7em 0}.cs-avatar{position:relative;width:42px;height:42px;border-radius:50%;box-sizing:border-box}.cs-avatar>img{box-sizing:border-box;width:100%;height:100%;border-radius:50%}.cs-avatar.cs-avatar--md{width:42px;height:42px;min-width:42px;min-height:42px\n",
              "</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can ask ChatGPT many times to get your own idea\n",
        "idea = '''\n",
        "Step 1: Data Preprocessing\n",
        "- Load the credit card database and examine the data.\n",
        "- Split the data into training and validation sets. I will employ a 5-fold cross-validation technique.\n",
        "\n",
        "Step 2: Model Training\n",
        "- Choose a decision tree-based model, such as a traditional decision tree, random forest, or gradient boosting.\n",
        "- Train the model using the training set.\n",
        "- Optimize the model's hyperparameters using techniques like grid search or random search. I will optimize the decision\n",
        "tree's hyperparameters, specifically 'max_leaf_nodes', with values [None, 5, 10, 15].\n",
        "\n",
        "Step 3: Model Prediction\n",
        "- Combine the predictions from all folds using an ensemble method, such as majority voting or averaging, to obtain the final prediction.\n",
        "'''\n",
        "prompt = '''\n",
        "I will use the following idea. What do you think?\n",
        "{idea}\n",
        "'''\n",
        "\n",
        "message = prompt.format(idea=idea)\n",
        "response = get_completion(message)\n",
        "\n",
        "html_content = generate_html(_messages)\n",
        "display(HTML(html_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "1dFA8pNh89Io",
        "outputId": "761f3e3e-bfc6-4a2d-a604-3ed12d8c8fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <section aria-label=\"User\" class=\"cs-message cs-message--outgoing cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/user-8c5a41ea.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">\n",
              "I will use the following idea. What do you think?\n",
              "\n",
              "Step 1: Data Preprocessing\n",
              "- Load the credit card database and examine the data.\n",
              "- Split the data into training and validation sets. I will employ a 5-fold cross-validation technique.\n",
              "\n",
              "Step 2: Model Training\n",
              "- Choose a decision tree-based model, such as a traditional decision tree, random forest, or gradient boosting.\n",
              "- Train the model using the training set.\n",
              "- Optimize the model&#x27;s hyperparameters using techniques like grid search or random search. I will optimize the decision\n",
              "tree&#x27;s hyperparameters, specifically &#x27;max_leaf_nodes&#x27;, with values [None, 5, 10, 15].\n",
              "\n",
              "Step 3: Model Prediction\n",
              "- Combine the predictions from all folds using an ensemble method, such as majority voting or averaging, to obtain the final prediction.\n",
              "\n",
              "</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    \n",
              "    <section aria-label=\"ChatGPT\" class=\"cs-message cs-message--incoming cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/chatbot-08b96590.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">Your proposed approach seems reasonable. Here are a few additional considerations:\n",
              "\n",
              "Step 1: Data Preprocessing\n",
              "- It&#x27;s important to handle missing values appropriately. Depending on the amount and nature of missing data, you can consider techniques like imputation, removal of missing data, or using models that can handle missing values directly (e.g., XGBoost).\n",
              "- If there are any outliers in the continuous features, you may need to handle them as well. Outliers can affect the performance of decision tree-based models.\n",
              "\n",
              "Step 2: Model Training\n",
              "- In addition to decision tree-based models, you can also consider ensemble methods like random forest or gradient boosting. These models often provide better performance by combining multiple decision trees.\n",
              "- Along with optimizing the hyperparameters of the decision tree, you can also explore hyperparameter optimization for ensemble models if you choose to use them.\n",
              "\n",
              "Step 3: Model Prediction\n",
              "- Ensemble methods like majority voting or averaging can be effective in reducing the variance and improving the stability of predictions. However, it&#x27;s important to ensure that the individual models in the ensemble are diverse enough to provide meaningful contributions.\n",
              "- Consider evaluating the performance of the model on the validation set using appropriate metrics (e.g., accuracy, precision, recall, or F1 score) to assess its effectiveness.\n",
              "\n",
              "Overall, your proposed approach is a good starting point. Just make sure to handle missing values, outliers, and evaluate the model&#x27;s performance using appropriate metrics.</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    <style>.cs-message{box-sizing:border-box;font-size:1em;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;color:#000000de;display:flex;flex-direction:row;padding:0;background-color:transparent;overflow:hidden;border-radius:0}.cs-message:not(:only-child){margin:.2em 0 0}.cs-message__avatar{box-sizing:border-box;margin:0 8px 0 0;display:flex;flex-direction:column;justify-content:flex-end;width:42px}.cs-message__content-wrapper{box-sizing:border-box;display:flex;flex-direction:column}.cs-message__content{box-sizing:border-box;color:#000000de;background-color:#c6e3fa;margin-top:0;padding:.6em .9em;border-radius:.7em;white-space:pre-wrap;overflow-wrap:anywhere;word-break:break-word;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;font-weight:400;font-size:.91em;font-variant:normal}.cs-message--incoming{color:#000000de;background-color:transparent;margin-right:auto}.cs-message--incoming .cs-message__avatar{margin:0 8px 0 0}.cs-message--incoming .cs-message__content{color:#000000de;background-color:#c6e3fa;border-radius:0 .7em .7em 0}.cs-message--outgoing{color:#000000de;background-color:transparent;margin-left:auto;justify-content:flex-end}.cs-message--outgoing .cs-message__avatar{order:1;margin:0 0 0 8px}.cs-message--outgoing .cs-message__content{color:#000000de;background-color:#6ea9d7;border-radius:.7em 0 0 .7em}.cs-message.cs-message--incoming.cs-message--single{border-radius:0}.cs-message.cs-message--incoming.cs-message--single:not(:first-child){margin-top:.4em}.cs-message.cs-message--incoming.cs-message--single .cs-message__content{border-radius:0 .7em .7em}.cs-message.cs-message--outgoing.cs-message--single{border-radius:0}.cs-message.cs-message--outgoing.cs-message--single .cs-message__content{border-radius:.7em .7em 0}.cs-avatar{position:relative;width:42px;height:42px;border-radius:50%;box-sizing:border-box}.cs-avatar>img{box-sizing:border-box;width:100%;height:100%;border-radius:50%}.cs-avatar.cs-avatar--md{width:42px;height:42px;min-width:42px;min-height:42px\n",
              "</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "# you may need to give ChatGPT some examples to start\n",
        "code_snippet_train = \"\"\"\n",
        "def make_grid(pars_dict):\n",
        "    keys = pars_dict.keys()\n",
        "    combinations = itertools.product(*pars_dict.values())\n",
        "    outputs = [dict(zip(keys, combination)) for combination in combinations]\n",
        "    return outputs\n",
        "\n",
        "param_grid = {\n",
        "    'max_leaf_nodes': [None, 5, 10, 15]\n",
        "}\n",
        "\n",
        "param_list = make_grid(param_grid)\n",
        "\n",
        "best_models = []\n",
        "for param in param_list:\n",
        "  '''\n",
        "  CODE HERE!\n",
        "  - evaluate under 5 fold cross validation\n",
        "  - save the model list (of five folds) with the best average performance\n",
        "  - ...\n",
        "  '''\n",
        "\"\"\"\n",
        "\n",
        "code_snippet_infer = \"\"\"\n",
        "for model in best_models:\n",
        "  '''\n",
        "  CODE HERE!\n",
        "  - use the model list for prediction\n",
        "  - use majority voting for ensemble\n",
        "  - ...\n",
        "  '''\n",
        "\"\"\"\n",
        "\n",
        "template = '''\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def read_data_from_csv(path):\n",
        "    \"\"\"Load datasets from CSV files.\n",
        "    Args:\n",
        "        path (str): Path to the CSV file.\n",
        "    Returns:\n",
        "        X (np.ndarray): Features of samples.\n",
        "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
        "    \"\"\"\n",
        "    assert os.path.exists(path), f'File not found: {{path}}!'\n",
        "    assert os.path.splitext(path)[\n",
        "        -1] == '.csv', f'Unsupported file type {{os.path.splitext(path)[-1]}}!'\n",
        "\n",
        "    data = pd.read_csv(path)\n",
        "    column_list = data.columns.values.tolist()\n",
        "\n",
        "    if 'Label' in column_list:\n",
        "        # for the public dataset, label column is provided.\n",
        "        column_list.remove('Label')\n",
        "        X = data[column_list].values\n",
        "        y = data['Label'].astype('int').values\n",
        "        return X, y\n",
        "    else:\n",
        "        # for the private dataset, label column is not provided.\n",
        "        X = data[column_list].values\n",
        "        return X\n",
        "\n",
        "X_public, y_public = read_data_from_csv('assignment_3_public.csv')\n",
        "print('Shape of X_public:', X_public.shape)  # n_sample, m_feature (590, 14)\n",
        "print('Shape of y_public:', y_public.shape)  # n_sample (590,)\n",
        "\n",
        "{code_snippet_train}\n",
        "\n",
        "X_private = read_data_from_csv('assignment_3_private.csv')\n",
        "print('Shape of X_private:', X_private.shape)  # k_sample, m_feature (100, 14)\n",
        "\n",
        "{code_snippet_infer}\n",
        "\n",
        "submission = pd.DataFrame({{'Label': preds}})\n",
        "submission.to_csv('assignment_3.csv', index=True, index_label='Id')\n",
        "'''\n",
        "\n",
        "prompt = '''\n",
        "Use the given code snippet to revise the code.\n",
        "{template}\n",
        "'''\n",
        "\n",
        "message = prompt.format(template=template.format(code_snippet_train=code_snippet_train, code_snippet_infer=code_snippet_infer))\n",
        "response = get_completion(message)\n",
        "\n",
        "html_content = generate_html(_messages)\n",
        "display(HTML(html_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H13Rz1D9HDjG",
        "outputId": "d955afab-aab4-49d3-bef4-a81a829618fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <section aria-label=\"User\" class=\"cs-message cs-message--outgoing cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/user-8c5a41ea.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">\n",
              "Use the given code snippet to revise the code.\n",
              "\n",
              "import os\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "\n",
              "def read_data_from_csv(path):\n",
              "    &quot;&quot;&quot;Load datasets from CSV files.\n",
              "    Args:\n",
              "        path (str): Path to the CSV file.\n",
              "    Returns:\n",
              "        X (np.ndarray): Features of samples.\n",
              "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
              "    &quot;&quot;&quot;\n",
              "    assert os.path.exists(path), f&#x27;File not found: {path}!&#x27;\n",
              "    assert os.path.splitext(path)[\n",
              "        -1] == &#x27;.csv&#x27;, f&#x27;Unsupported file type {os.path.splitext(path)[-1]}!&#x27;\n",
              "\n",
              "    data = pd.read_csv(path)\n",
              "    column_list = data.columns.values.tolist()\n",
              "\n",
              "    if &#x27;Label&#x27; in column_list:\n",
              "        # for the public dataset, label column is provided.\n",
              "        column_list.remove(&#x27;Label&#x27;)\n",
              "        X = data[column_list].values\n",
              "        y = data[&#x27;Label&#x27;].astype(&#x27;int&#x27;).values\n",
              "        return X, y\n",
              "    else:\n",
              "        # for the private dataset, label column is not provided.\n",
              "        X = data[column_list].values\n",
              "        return X\n",
              "\n",
              "X_public, y_public = read_data_from_csv(&#x27;assignment_3_public.csv&#x27;)\n",
              "print(&#x27;Shape of X_public:&#x27;, X_public.shape)  # n_sample, m_feature (590, 14)\n",
              "print(&#x27;Shape of y_public:&#x27;, y_public.shape)  # n_sample (590,)\n",
              "\n",
              "\n",
              "def make_grid(pars_dict):\n",
              "    keys = pars_dict.keys()\n",
              "    combinations = itertools.product(*pars_dict.values())\n",
              "    outputs = [dict(zip(keys, combination)) for combination in combinations]\n",
              "    return outputs\n",
              "\n",
              "param_grid = {\n",
              "    &#x27;max_leaf_nodes&#x27;: [None, 5, 10, 15]\n",
              "}\n",
              "\n",
              "param_list = make_grid(param_grid)\n",
              "\n",
              "best_models = []\n",
              "for param in param_list:\n",
              "  &#x27;&#x27;&#x27;\n",
              "  CODE HERE!\n",
              "  - evaluate under 5 fold cross validation\n",
              "  - save the model list (of five folds) with the best average performance\n",
              "  - ...\n",
              "  &#x27;&#x27;&#x27;\n",
              "\n",
              "\n",
              "X_private = read_data_from_csv(&#x27;assignment_3_private.csv&#x27;)\n",
              "print(&#x27;Shape of X_private:&#x27;, X_private.shape)  # k_sample, m_feature (100, 14)\n",
              "\n",
              "\n",
              "for model in best_models:\n",
              "  &#x27;&#x27;&#x27;\n",
              "  CODE HERE!\n",
              "  - use the model list for prediction\n",
              "  - use majority voting for ensemble\n",
              "  - ...\n",
              "  &#x27;&#x27;&#x27;\n",
              "\n",
              "\n",
              "submission = pd.DataFrame({&#x27;Label&#x27;: preds})\n",
              "submission.to_csv(&#x27;assignment_3.csv&#x27;, index=True, index_label=&#x27;Id&#x27;)\n",
              "\n",
              "</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    \n",
              "    <section aria-label=\"ChatGPT\" class=\"cs-message cs-message--incoming cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/chatbot-08b96590.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">Here&#x27;s a revised version of the code snippet:\n",
              "\n",
              "```python\n",
              "import os\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "import itertools\n",
              "from sklearn.tree import DecisionTreeClassifier\n",
              "from sklearn.model_selection import cross_val_score\n",
              "\n",
              "def read_data_from_csv(path):\n",
              "    &quot;&quot;&quot;Load datasets from CSV files.\n",
              "    Args:\n",
              "        path (str): Path to the CSV file.\n",
              "    Returns:\n",
              "        X (np.ndarray): Features of samples.\n",
              "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
              "    &quot;&quot;&quot;\n",
              "    assert os.path.exists(path), f&#x27;File not found: {path}!&#x27;\n",
              "    assert os.path.splitext(path)[-1] == &#x27;.csv&#x27;, f&#x27;Unsupported file type {os.path.splitext(path)[-1]}!&#x27;\n",
              "\n",
              "    data = pd.read_csv(path)\n",
              "    column_list = data.columns.values.tolist()\n",
              "\n",
              "    if &#x27;Label&#x27; in column_list:\n",
              "        # for the public dataset, label column is provided.\n",
              "        column_list.remove(&#x27;Label&#x27;)\n",
              "        X = data[column_list].values\n",
              "        y = data[&#x27;Label&#x27;].astype(&#x27;int&#x27;).values\n",
              "        return X, y\n",
              "    else:\n",
              "        # for the private dataset, label column is not provided.\n",
              "        X = data[column_list].values\n",
              "        return X\n",
              "\n",
              "X_public, y_public = read_data_from_csv(&#x27;assignment_3_public.csv&#x27;)\n",
              "print(&#x27;Shape of X_public:&#x27;, X_public.shape)  # n_sample, m_feature (590, 14)\n",
              "print(&#x27;Shape of y_public:&#x27;, y_public.shape)  # n_sample (590,)\n",
              "\n",
              "def make_grid(pars_dict):\n",
              "    keys = pars_dict.keys()\n",
              "    combinations = itertools.product(*pars_dict.values())\n",
              "    outputs = [dict(zip(keys, combination)) for combination in combinations]\n",
              "    return outputs\n",
              "\n",
              "param_grid = {\n",
              "    &#x27;max_leaf_nodes&#x27;: [None, 5, 10, 15]\n",
              "}\n",
              "\n",
              "param_list = make_grid(param_grid)\n",
              "\n",
              "best_models = []\n",
              "best_avg_score = 0\n",
              "\n",
              "for param in param_list:\n",
              "    model = DecisionTreeClassifier(**param)\n",
              "    scores = cross_val_score(model, X_public, y_public, cv=5)\n",
              "    avg_score = np.mean(scores)\n",
              "    if avg_score &gt; best_avg_score:\n",
              "        best_avg_score = avg_score\n",
              "        best_models = [model]\n",
              "    elif avg_score == best_avg_score:\n",
              "        best_models.append(model)\n",
              "\n",
              "X_private = read_data_from_csv(&#x27;assignment_3_private.csv&#x27;)\n",
              "print(&#x27;Shape of X_private:&#x27;, X_private.shape)  # k_sample, m_feature (100, 14)\n",
              "\n",
              "preds = []\n",
              "for model in best_models:\n",
              "    pred = model.predict(X_private)\n",
              "    preds.append(pred)\n",
              "\n",
              "preds = np.array(preds)\n",
              "final_pred = np.mean(preds, axis=0)\n",
              "final_pred = np.round(final_pred).astype(int)\n",
              "\n",
              "submission = pd.DataFrame({&#x27;Label&#x27;: final_pred})\n",
              "submission.to_csv(&#x27;assignment_3.csv&#x27;, index=True, index_label=&#x27;Id&#x27;)\n",
              "```\n",
              "\n",
              "In this revised code, I have added the following changes:\n",
              "\n",
              "1. Imported the necessary libraries, including `itertools` for creating parameter combinations and `DecisionTreeClassifier` for the decision tree-based model.\n",
              "2. Used `cross_val_score` to perform 5-fold cross-validation and evaluate the model&#x27;s performance.\n",
              "3. Stored the best models based on the average cross-validation score.\n",
              "4. Predicted the labels for the private dataset using the best models and performed majority voting to obtain the final prediction.\n",
              "5. Saved the final predictions in a CSV file named &#x27;assignment_3.csv&#x27; with the required format.\n",
              "\n",
              "Please note that you may need to modify the code further based on your specific requirements and the structure of your dataset.</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    <style>.cs-message{box-sizing:border-box;font-size:1em;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;color:#000000de;display:flex;flex-direction:row;padding:0;background-color:transparent;overflow:hidden;border-radius:0}.cs-message:not(:only-child){margin:.2em 0 0}.cs-message__avatar{box-sizing:border-box;margin:0 8px 0 0;display:flex;flex-direction:column;justify-content:flex-end;width:42px}.cs-message__content-wrapper{box-sizing:border-box;display:flex;flex-direction:column}.cs-message__content{box-sizing:border-box;color:#000000de;background-color:#c6e3fa;margin-top:0;padding:.6em .9em;border-radius:.7em;white-space:pre-wrap;overflow-wrap:anywhere;word-break:break-word;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;font-weight:400;font-size:.91em;font-variant:normal}.cs-message--incoming{color:#000000de;background-color:transparent;margin-right:auto}.cs-message--incoming .cs-message__avatar{margin:0 8px 0 0}.cs-message--incoming .cs-message__content{color:#000000de;background-color:#c6e3fa;border-radius:0 .7em .7em 0}.cs-message--outgoing{color:#000000de;background-color:transparent;margin-left:auto;justify-content:flex-end}.cs-message--outgoing .cs-message__avatar{order:1;margin:0 0 0 8px}.cs-message--outgoing .cs-message__content{color:#000000de;background-color:#6ea9d7;border-radius:.7em 0 0 .7em}.cs-message.cs-message--incoming.cs-message--single{border-radius:0}.cs-message.cs-message--incoming.cs-message--single:not(:first-child){margin-top:.4em}.cs-message.cs-message--incoming.cs-message--single .cs-message__content{border-radius:0 .7em .7em}.cs-message.cs-message--outgoing.cs-message--single{border-radius:0}.cs-message.cs-message--outgoing.cs-message--single .cs-message__content{border-radius:.7em .7em 0}.cs-avatar{position:relative;width:42px;height:42px;border-radius:50%;box-sizing:border-box}.cs-avatar>img{box-sizing:border-box;width:100%;height:100%;border-radius:50%}.cs-avatar.cs-avatar--md{width:42px;height:42px;min-width:42px;min-height:42px\n",
              "</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "ideas = '''\n",
        "- I have observed that there are missing values in the dataset and am considering\n",
        "implementing various strategies for imputation, such as median imputation and\n",
        "most_frequent imputation.\n",
        "\n",
        "- Moreover, I noticed that the dataset contains both categorical and continuous\n",
        "variables, and hence, I am contemplating utilizing different strategies for\n",
        "their representation. For instance, one-hot encoding can be employed for\n",
        "categorical variables.\n",
        "\n",
        "- These designs should be explored to determine their utility, and as such,\n",
        "the code can be modified accordingly:\n",
        "\n",
        "param_grid = {\n",
        "    'max_leaf_nodes': [None, 5, 10, 15],\n",
        "    'imputer': [None, 'median', 'most_frequent'],\n",
        "    'category': [None, 'onehot'],\n",
        "    'continuous': [None, 'binning']\n",
        "}\n",
        "'''\n",
        "\n",
        "prompt = '''\n",
        "Consider modifying the code according to the ideas below to enhance performance.\n",
        "{ideas}\n",
        "'''\n",
        "message = prompt.format(ideas=ideas)\n",
        "response = get_completion(message)\n",
        "\n",
        "html_content = generate_html(_messages)\n",
        "display(HTML(html_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wWNMdoh3Au5n",
        "outputId": "58ba70e7-f0f3-4740-f8ac-23abaa9ecae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <section aria-label=\"User\" class=\"cs-message cs-message--outgoing cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/user-8c5a41ea.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">\n",
              "Consider modifying the code according to the ideas below to enhance performance.\n",
              "\n",
              "- I have observed that there are missing values in the dataset and am considering\n",
              "implementing various strategies for imputation, such as median imputation and\n",
              "most_frequent imputation.\n",
              "\n",
              "- Moreover, I noticed that the dataset contains both categorical and continuous\n",
              "variables, and hence, I am contemplating utilizing different strategies for\n",
              "their representation. For instance, one-hot encoding can be employed for\n",
              "categorical variables.\n",
              "\n",
              "- These designs should be explored to determine their utility, and as such,\n",
              "the code can be modified accordingly:\n",
              "\n",
              "param_grid = {\n",
              "    &#x27;max_leaf_nodes&#x27;: [None, 5, 10, 15],\n",
              "    &#x27;imputer&#x27;: [None, &#x27;median&#x27;, &#x27;most_frequent&#x27;],\n",
              "    &#x27;category&#x27;: [None, &#x27;onehot&#x27;],\n",
              "    &#x27;continuous&#x27;: [None, &#x27;binning&#x27;]\n",
              "}\n",
              "\n",
              "</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    \n",
              "    <section aria-label=\"ChatGPT\" class=\"cs-message cs-message--incoming cs-message--single\" data-cs-message=\"\">\n",
              "        <div class=\"cs-message__avatar\">\n",
              "            <div class=\"cs-avatar cs-avatar--md\"><img src=\"https://genai.polyu.edu.hk/assets/chatbot-08b96590.png\" alt=\"PolyU\"> </div>\n",
              "        </div>\n",
              "        <div class=\"cs-message__content-wrapper\">\n",
              "            <div class=\"cs-message__content\">\n",
              "                <div class=\"cs-message__custom-content\">Here&#x27;s the modified code snippet based on your ideas:\n",
              "\n",
              "```python\n",
              "import os\n",
              "import numpy as np\n",
              "import pandas as pd\n",
              "import itertools\n",
              "from sklearn.tree import DecisionTreeClassifier\n",
              "from sklearn.model_selection import cross_val_score\n",
              "from sklearn.impute import SimpleImputer\n",
              "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
              "from sklearn.compose import ColumnTransformer\n",
              "from sklearn.pipeline import Pipeline\n",
              "\n",
              "def read_data_from_csv(path):\n",
              "    &quot;&quot;&quot;Load datasets from CSV files.\n",
              "    Args:\n",
              "        path (str): Path to the CSV file.\n",
              "    Returns:\n",
              "        X (np.ndarray): Features of samples.\n",
              "        y (np.ndarray): Labels of samples, only provided in the public datasets.\n",
              "    &quot;&quot;&quot;\n",
              "    assert os.path.exists(path), f&#x27;File not found: {path}!&#x27;\n",
              "    assert os.path.splitext(path)[-1] == &#x27;.csv&#x27;, f&#x27;Unsupported file type {os.path.splitext(path)[-1]}!&#x27;\n",
              "\n",
              "    data = pd.read_csv(path)\n",
              "    column_list = data.columns.values.tolist()\n",
              "\n",
              "    if &#x27;Label&#x27; in column_list:\n",
              "        # for the public dataset, label column is provided.\n",
              "        column_list.remove(&#x27;Label&#x27;)\n",
              "        X = data[column_list].values\n",
              "        y = data[&#x27;Label&#x27;].astype(&#x27;int&#x27;).values\n",
              "        return X, y\n",
              "    else:\n",
              "        # for the private dataset, label column is not provided.\n",
              "        X = data[column_list].values\n",
              "        return X\n",
              "\n",
              "X_public, y_public = read_data_from_csv(&#x27;assignment_3_public.csv&#x27;)\n",
              "print(&#x27;Shape of X_public:&#x27;, X_public.shape)  # n_sample, m_feature (590, 14)\n",
              "print(&#x27;Shape of y_public:&#x27;, y_public.shape)  # n_sample (590,)\n",
              "\n",
              "def make_grid(pars_dict):\n",
              "    keys = pars_dict.keys()\n",
              "    combinations = itertools.product(*pars_dict.values())\n",
              "    outputs = [dict(zip(keys, combination)) for combination in combinations]\n",
              "    return outputs\n",
              "\n",
              "param_grid = {\n",
              "    &#x27;max_leaf_nodes&#x27;: [None, 5, 10, 15],\n",
              "    &#x27;imputer&#x27;: [None, &#x27;median&#x27;, &#x27;most_frequent&#x27;],\n",
              "    &#x27;category&#x27;: [None, &#x27;onehot&#x27;],\n",
              "    &#x27;continuous&#x27;: [None, &#x27;binning&#x27;]\n",
              "}\n",
              "\n",
              "param_list = make_grid(param_grid)\n",
              "\n",
              "best_models = []\n",
              "best_avg_score = 0\n",
              "\n",
              "for param in param_list:\n",
              "    imputer = None\n",
              "    if param[&#x27;imputer&#x27;] == &#x27;median&#x27;:\n",
              "        imputer = SimpleImputer(strategy=&#x27;median&#x27;)\n",
              "    elif param[&#x27;imputer&#x27;] == &#x27;most_frequent&#x27;:\n",
              "        imputer = SimpleImputer(strategy=&#x27;most_frequent&#x27;)\n",
              "    \n",
              "    category_transformer = None\n",
              "    if param[&#x27;category&#x27;] == &#x27;onehot&#x27;:\n",
              "        category_transformer = OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)\n",
              "    \n",
              "    continuous_transformer = None\n",
              "    if param[&#x27;continuous&#x27;] == &#x27;binning&#x27;:\n",
              "        continuous_transformer = KBinsDiscretizer(n_bins=5, encode=&#x27;ordinal&#x27;)\n",
              "    \n",
              "    preprocessor = ColumnTransformer(\n",
              "        transformers=[\n",
              "            (&#x27;imputer&#x27;, imputer, slice(0, 6)),  # Assuming the first 6 columns are continuous features\n",
              "            (&#x27;category&#x27;, category_transformer, [6, 7, 8, 9, 10, 11]),\n",
              "            (&#x27;continuous&#x27;, continuous_transformer, slice(0, 6))\n",
              "        ]\n",
              "    )\n",
              "    \n",
              "    model = Pipeline(\n",
              "        steps=[\n",
              "            (&#x27;preprocessor&#x27;, preprocessor),\n",
              "            (&#x27;classifier&#x27;, DecisionTreeClassifier(max_leaf_nodes=param[&#x27;max_leaf_nodes&#x27;]))\n",
              "        ]\n",
              "    )\n",
              "    \n",
              "    scores = cross_val_score(model, X_public, y_public, cv=5)\n",
              "    avg_score = np.mean(scores)\n",
              "    if avg_score &gt; best_avg_score:\n",
              "        best_avg_score = avg_score\n",
              "        best_models = [model]\n",
              "    elif avg_score == best_avg_score:\n",
              "        best_models.append(model)\n",
              "\n",
              "X_private = read_data_from_csv(&#x27;assignment_3_private.csv&#x27;)\n",
              "print(&#x27;Shape of X_private:&#x27;, X_private.shape)  # k_sample, m_feature (100, 14)\n",
              "\n",
              "preds = []\n",
              "for model in best_models:\n",
              "    pred = model.predict(X_private)\n",
              "    preds.append(pred)\n",
              "\n",
              "preds = np.array(preds)\n",
              "final_pred = np.mean(preds, axis=0)\n",
              "final_pred = np.round(final_pred).astype(int)\n",
              "\n",
              "submission = pd.DataFrame({&#x27;Label&#x27;: final_pred})\n",
              "submission.to_csv(&#x27;assignment_3.csv&#x27;, index=True, index_label=&#x27;Id&#x27;)\n",
              "```\n",
              "\n",
              "In this modified code, I have made the following changes:\n",
              "\n",
              "1. Imported the necessary libraries, including `SimpleImputer` for handling missing values, `OneHotEncoder` for one-hot encoding categorical variables, and `KBinsDiscretizer` for binning continuous variables.\n",
              "2. Created a `ColumnTransformer` to apply different preprocessing strategies to different subsets of features.\n",
              "3. Constructed a `Pipeline` that combines the preprocessing steps with the decision tree classifier.\n",
              "4. Modified the parameter grid to include options for imputation, categorical encoding, and continuous variable representation.\n",
              "5. Updated the model creation process to incorporate the preprocessing steps based on the selected options from the parameter grid.\n",
              "\n",
              "Please note that you may need to adjust the column indices in the `ColumnTransformer` based on the actual positions of the continuous and categorical features in your dataset. Additionally, you can further customize the preprocessing steps and model parameters based on your specific requirements.</div>\n",
              "            </div>\n",
              "        </div>\n",
              "    </section>\n",
              "    <style>.cs-message{box-sizing:border-box;font-size:1em;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;color:#000000de;display:flex;flex-direction:row;padding:0;background-color:transparent;overflow:hidden;border-radius:0}.cs-message:not(:only-child){margin:.2em 0 0}.cs-message__avatar{box-sizing:border-box;margin:0 8px 0 0;display:flex;flex-direction:column;justify-content:flex-end;width:42px}.cs-message__content-wrapper{box-sizing:border-box;display:flex;flex-direction:column}.cs-message__content{box-sizing:border-box;color:#000000de;background-color:#c6e3fa;margin-top:0;padding:.6em .9em;border-radius:.7em;white-space:pre-wrap;overflow-wrap:anywhere;word-break:break-word;font-family:Helvetica Neue,Segoe UI,Helvetica,Arial,sans-serif;font-weight:400;font-size:.91em;font-variant:normal}.cs-message--incoming{color:#000000de;background-color:transparent;margin-right:auto}.cs-message--incoming .cs-message__avatar{margin:0 8px 0 0}.cs-message--incoming .cs-message__content{color:#000000de;background-color:#c6e3fa;border-radius:0 .7em .7em 0}.cs-message--outgoing{color:#000000de;background-color:transparent;margin-left:auto;justify-content:flex-end}.cs-message--outgoing .cs-message__avatar{order:1;margin:0 0 0 8px}.cs-message--outgoing .cs-message__content{color:#000000de;background-color:#6ea9d7;border-radius:.7em 0 0 .7em}.cs-message.cs-message--incoming.cs-message--single{border-radius:0}.cs-message.cs-message--incoming.cs-message--single:not(:first-child){margin-top:.4em}.cs-message.cs-message--incoming.cs-message--single .cs-message__content{border-radius:0 .7em .7em}.cs-message.cs-message--outgoing.cs-message--single{border-radius:0}.cs-message.cs-message--outgoing.cs-message--single .cs-message__content{border-radius:.7em .7em 0}.cs-avatar{position:relative;width:42px;height:42px;border-radius:50%;box-sizing:border-box}.cs-avatar>img{box-sizing:border-box;width:100%;height:100%;border-radius:50%}.cs-avatar.cs-avatar--md{width:42px;height:42px;min-width:42px;min-height:42px\n",
              "</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QF5oLYrYVnv"
      },
      "source": [
        "## Private test cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SFVinYSYVnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204a291e-3607-460b-85fe-292baf378aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_private: (100, 14)\n"
          ]
        }
      ],
      "source": [
        "X_private = read_data_from_csv('assignment_3_private.csv')\n",
        "print('Shape of X_private:', X_private.shape)  # k_sample, m_feature (100, 14)\n",
        "\n",
        "if best_imputer is not None:\n",
        "    X_private = best_imputer.transform(X_private)\n",
        "\n",
        "if best_category is not None:\n",
        "    X_private = np.concatenate([X_private[:, :6], best_category.transform(X_private[:, 6:])], axis=1)\n",
        "\n",
        "# use best models for ensemble.\n",
        "preds = []\n",
        "for model in best_models:\n",
        "    pred = model.predict(X_private)\n",
        "    preds.append(pred.tolist())\n",
        "\n",
        "# use majority voting for ensemble.\n",
        "preds = np.array(preds)\n",
        "preds = np.sum(preds, axis=0)\n",
        "preds = np.where(preds > len(best_models) / 2, 1, 0)\n",
        "\n",
        "# save your predictions in a CSV file.\n",
        "submission = pd.DataFrame({'Label': preds})\n",
        "submission.to_csv('assignment_3.csv', index=True, index_label='Id')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read pred from csv file.\n",
        "\n",
        "preds = pd.read_csv('assignment_3.csv')['Label'].values\n",
        "\n",
        "# check the accuracy of your predictions.\n",
        "\n",
        "X_private, y_private = read_data_from_csv('assignment_3_private_gt.csv')\n",
        "print('Accuracy:', np.sum(preds == y_private) / len(y_private))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pls6JxyPOdE2",
        "outputId": "2b60e25e-9d48-4917-e1c2-522e4dac9914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hX_5-xK3PNgi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}